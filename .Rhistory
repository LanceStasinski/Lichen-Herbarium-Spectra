name = paste(uniqueNames[j], "vip", sep = ".")
vip.list = list.append(vip.list, assign(name, matrix(nrow = 896)))
}
#start of PLSDA code
for(i in 1:1){
#create data partition: 70% of data for training, 30% for testing
inTrain <- caret::createDataPartition(
y = spec_df[[className]],
p = .7,
list = FALSE
)
training <- spec_df[inTrain,]
testing <- spec_df[-inTrain,]
#tune model: 10-fold cross-validation repeated 3 times
ctrl <- trainControl(
method = "repeatedcv",
number = 10,
sampling = resampling,
repeats = 3)
#Fit model. Note max iterations set to 100000 to allow model convergence
plsFit <- train(
as.formula(paste(className, "~ .")),
data = training,
maxit = 100000,
method = "pls",
trControl = ctrl,
tuneLength = ncomp)
#variable importance
vip = varImp(plsFit)
for (k in 1:length(uniqueNames)) {
class.vip = assign(paste0(uniqueNames[k], i), vip$importance[uniqueNames[k]])
vip.list[[k]] = cbind(vip.list[[k]], get('class.vip'))
}
results = list.append(results, vip.list)
#accuracy objects for determining n components
a = assign(paste0('a', i), as.matrix(plsFit$results$Accuracy))
a.fit <- cbind(a.fit, get('a'))
results = list.append(results, a.fit)
#test model using the testing data partition (20% of data)
plsClasses <- predict(plsFit, newdata = testing)
#confusion/classification matrix objects to assess accuracy
cm = confusionMatrix(data = plsClasses, as.factor(testing[[className]]))
cm.m = assign(paste0("cm", i), as.matrix(cm))
cm.list <- list.append(cm.list, get('cm.m'))
results = list.append(results, cm.list)
ac <- assign(paste0('acc',i), cm$overall[1])
accuracy <- append(accuracy, get('ac'))
results = list.append(results, accuracy)
kap = assign(paste0("kap",i), cm$overall[2])
kappa <- append(kappa, get('kap'))
results = list.append(results, kappa)
return(results)
}
}
saveRDS(classify, "functions/plsda.rds")
classify = readRDS("functions/plsda.rds")
classify = readRDS("functions/plsda.rds")
pls = classify(file = "spectra/lichen_spectra.rds",
className = "scientificName",
ncomp = 3, resampling = 'down')
pls
classify = function(file, className, ncomp, resampling, n_iteration) {
#require packages
require(spectrolab)
require(caret)
require(dplyr)
require(rlist)
require(matrixStats)
require(mlbench)
#load spectra and convert to matrix and dataframe
spec_all = readRDS(file)
spec_mat = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#combine relevant meta data to matrix
spec_df = as.data.frame(spec_mat)
spec_df = cbind(spec_df, spec_all.df[className])
colnames(spec_df)[colnames(spec_df) == className] <- className
uniqueNames = unique(spec_all.df[[className]])
##################
#Run PLSDA
##################
#create vectors, lists, and matrices to store metrics and variable importance
accuracy = c()
kappa = c()
a.fit = matrix(nrow = ncomp)
cm.list = list()
vip.list = list()
results = list()
#create variable importance matrix for each class
for(j in 1:length(uniqueNames)){
name = paste(uniqueNames[j], "vip", sep = ".")
vip.list = list.append(vip.list, assign(name, matrix(nrow = 896)))
}
#start of PLSDA code
for(i in 1:n_iteration){
#create data partition: 70% of data for training, 30% for testing
inTrain <- caret::createDataPartition(
y = spec_df[[className]],
p = .7,
list = FALSE
)
training <- spec_df[inTrain,]
testing <- spec_df[-inTrain,]
#tune model: 10-fold cross-validation repeated 3 times
ctrl <- trainControl(
method = "repeatedcv",
number = 10,
sampling = resampling,
repeats = 3)
#Fit model. Note max iterations set to 100000 to allow model convergence
plsFit <- train(
as.formula(paste(className, "~ .")),
data = training,
maxit = 100000,
method = "pls",
trControl = ctrl,
tuneLength = ncomp)
#variable importance
vip = varImp(plsFit)
for (k in 1:length(uniqueNames)) {
class.vip = assign(paste0(uniqueNames[k], i), vip$importance[uniqueNames[k]])
vip.list[[k]] = cbind(vip.list[[k]], get('class.vip'))
}
results = list.append(results, vip.list)
#accuracy objects for determining n components
a = assign(paste0('a', i), as.matrix(plsFit$results$Accuracy))
a.fit <- cbind(a.fit, get('a'))
results = list.append(results, a.fit)
#test model using the testing data partition (20% of data)
plsClasses <- predict(plsFit, newdata = testing)
#confusion/classification matrix objects to assess accuracy
cm = confusionMatrix(data = plsClasses, as.factor(testing[[className]]))
cm.m = assign(paste0("cm", i), as.matrix(cm))
cm.list <- list.append(cm.list, get('cm.m'))
results = list.append(results, cm.list)
ac <- assign(paste0('acc',i), cm$overall[1])
accuracy <- append(accuracy, get('ac'))
results = list.append(results, accuracy)
kap = assign(paste0("kap",i), cm$overall[2])
kappa <- append(kappa, get('kap'))
results = list.append(results, kappa)
return(results)
}
}
saveRDS(classify, "functions/plsda.rds")
classify = readRDS("functions/plsda.rds")
library(corrplot)
library(matrixStats)
library(naniar)
################################################################################
#run plsda
################################################################################
classify = readRDS("functions/plsda.rds")
pls = classify(file = "spectra/lichen_spectra.rds",
className = "scientificName",
ncomp = 3,
resampling = 'down',
n_iteration = 3)
################################################################################
#Assess accuracy and kappa
################################################################################
accuracy = pls[[4]]
pls
################################################################################
#Caret PLSDA single function
##This function takes in a spectra file name, the name of the column to be
#classified, the number of components to use, the type of resampling to be
#done ('up' or 'down'), and the number of iterations to complete. The function
#will return a list object that contains a list of matrices containing variable
#importance values for each species, a matrix of model accuracy
#(rows = components, columns = iteration), and vectors for overall accuracy and
#kappa statistics.
################################################################################
classify = function(file, className, ncomp, resampling, n_iteration) {
#require packages
require(spectrolab)
require(caret)
require(dplyr)
require(rlist)
require(matrixStats)
require(mlbench)
#load spectra and convert to matrix and dataframe
spec_all = readRDS(file)
spec_mat = as.matrix(spec_all)
spec_all.df = as.data.frame(spec_all)
#combine relevant meta data to matrix
spec_df = as.data.frame(spec_mat)
spec_df = cbind(spec_df, spec_all.df[className])
colnames(spec_df)[colnames(spec_df) == className] <- className
uniqueNames = unique(spec_all.df[[className]])
##################
#Run PLSDA
##################
#create vectors, lists, and matrices to store metrics and variable importance
accuracy = c()
kappa = c()
a.fit = matrix(nrow = ncomp)
cm.list = list()
vip.list = list()
results = list()
#create variable importance matrix for each class
for(j in 1:length(uniqueNames)){
name = paste(uniqueNames[j], "vip", sep = ".")
vip.list = list.append(vip.list, assign(name, matrix(nrow = 896)))
}
#start of PLSDA code
for(i in 1:n_iteration){
#create data partition: 70% of data for training, 30% for testing
inTrain <- caret::createDataPartition(
y = spec_df[[className]],
p = .7,
list = FALSE
)
training <- spec_df[inTrain,]
testing <- spec_df[-inTrain,]
#tune model: 10-fold cross-validation repeated 3 times
ctrl <- trainControl(
method = "repeatedcv",
number = 10,
sampling = resampling,
repeats = 3)
#Fit model. Note max iterations set to 100000 to allow model convergence
plsFit <- train(
as.formula(paste(className, "~ .")),
data = training,
maxit = 100000,
method = "pls",
trControl = ctrl,
tuneLength = ncomp)
#variable importance
vip = varImp(plsFit)
for (k in 1:length(uniqueNames)) {
class.vip = assign(paste0(uniqueNames[k], i), vip$importance[uniqueNames[k]])
vip.list[[k]] = cbind(vip.list[[k]], get('class.vip'))
}
#accuracy objects for determining n components
a = assign(paste0('a', i), as.matrix(plsFit$results$Accuracy))
a.fit <- cbind(a.fit, get('a'))
#test model using the testing data partition (20% of data)
plsClasses <- predict(plsFit, newdata = testing)
#confusion/classification matrix objects to assess accuracy
cm = confusionMatrix(data = plsClasses, as.factor(testing[[className]]))
cm.m = assign(paste0("cm", i), as.matrix(cm))
cm.list <- list.append(cm.list, get('cm.m'))
ac <- assign(paste0('acc',i), cm$overall[1])
accuracy <- append(accuracy, get('ac'))
kap = assign(paste0("kap",i), cm$overall[2])
kappa <- append(kappa, get('kap'))
}
results = list.append(results, vip.list)
results = list.append(results, a.fit)
results = list.append(results, cm.list)
results = list.append(results, accuracy)
results = list.append(results, kappa)
return(results)
}
saveRDS(classify, "functions/plsda.rds")
classify = readRDS("functions/plsda.rds")
pls = classify(file = "spectra/lichen_spectra.rds",
className = "scientificName",
ncomp = 3,
resampling = 'down',
n_iteration = 3)
################################################################################
#Assess accuracy and kappa
################################################################################
accuracy = pls[[4]]
mean.acc = mean(accuracy)
(.217 + .108 + .137)/3
sd.acc = sd(accuracy)
mean(accuracy)
kappa = pls[[5]]
mean(kappa)
sd(kappa)
View(pls)
pls[[2]]
################################################################################
#Accuracy values for choosing the optimal number of components to use
################################################################################
a.fit = pls[[2]]
a.fit
a.total = a.fit[,-1]
View(a.total)
a.avg = as.matrix(rowMeans(a.total))
a.sd = as.matrix(rowSds(a.total))
a.lower = a.avg - a.sd
a.higher = a.avg + a.sd
#Graph to visually choose optimal number of components
x = 1:3
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
plot(x, a.avg, type = 'p', pch = 16, cex = .75, ylab = 'Accuracy',
xlab = 'Component', xlim = c(1,60), main = 'Accuracy for Species_ID',
ylim = c(0,1))
arrows(x, a.lower, x, a.higher,length=0.05, angle=90, code=3)
abline(v = 9, col = 'blue')
abline(h = max(a.avg), col = "Red")
legend('bottomright', legend = c('Mean', 'Maximum accuracy','Best component'),
pch = c(16, NA, NA), lty = c(NA, 1, 1), col = c('black', 'red', 'blue'))
which.max(a.avg)
x = 1:3
par(mar = c(5.1, 4.1, 4.1, 2.1), oma = c(5.1, 4.1, 4.1, 2.1))
plot(x, a.avg, type = 'p', pch = 16, cex = .75, ylab = 'Accuracy',
xlab = 'Component', xlim = c(1,60), main = 'Accuracy for Species_ID',
ylim = c(0,1))
arrows(x, a.lower, x, a.higher,length=0.05, angle=90, code=3)
abline(v = which.max(a.avg), col = 'blue')
abline(h = max(a.avg), col = "Red")
legend('bottomright', legend = c('Mean', 'Maximum accuracy','Best component'),
pch = c(16, NA, NA), lty = c(NA, 1, 1), col = c('black', 'red', 'blue'))
pls[[3]]
################################################################################
#Confusion/Classification Matrices
################################################################################
#take average of confusion matrices, reorient matrix, change averages to
#proportions
cm.list = pls[[3]]
cm.avg = Reduce('+', cm.list)/100
cm.avg = t(cm.avg)
cm.total = cm.avg/rowSums(cm.avg)
cm.list[1]
rownames(cm.list[1])
m = as.matrix(cm.list[1])
m
View(m)
m[2]
m = as.matrix(cm.list[[1]])
m
View(m)
rownames(m)
f1 <- function(lst){
n <- length(lst);
rc <- dim(lst[[1]]);
ar1 <- array(unlist(lst), c(rc, n));
round(apply(ar1, c(1, 2), sd), 2);
}
cm.sd = f1(cm.list)
cm.sd = t(cm.sd)
cm.sd = cm.sd/rowSums(cm.avg)
rownames(cm.sd) = rownames(as.matrix(cm.list[[1]]))
colnames(cm.sd) = colnamse(as.matrix(cm.list[[1]]))
colnames(cm.sd) = colnames(as.matrix(cm.list[[1]]))
View(cm.sd)
View(cm.total)
cm.total = as.data.frame(cm.total)
cm.total = cm.total %>% replace_with_na_all(condition = ~.x == 0)
cm.total = as.matrix(cm.total)
rownames(cm.total) = rownames(as.matrix(cm.list[[1]]))
colnames(cm.total) = colnames(as.matrix(cm.list[[1]]))
View(cm.total)
cols = colorRampPalette(c('#f5f5f5', '#fe9929'))
par(mfrow = c(1,1))
corrplot::corrplot(cm.total,
is.corr = F,
method = 'square',
col = cols(10),
addCoef.col = '#542788',
tl.srt = 0,
tl.offset = 1,
number.digits = 2,
tl.cex = 1.2,
cl.cex = 1,
number.cex = 1.5,
tl.col = 'black',
cl.pos = 'n',
cl.lim = c(0,1),
na.label = 'square',
na.label.col = 'white',
addgrid.col = 'grey')
View(cm.total)
str(cm.total)
b = as.matrix(cm.total)
b
str(b)
corrplot::corrplot(cm.total,
is.corr = T,
method = 'square',
col = cols(10),
addCoef.col = '#542788',
tl.srt = 0,
tl.offset = 1,
number.digits = 2,
tl.cex = 1.2,
cl.cex = 1,
number.cex = 1.5,
tl.col = 'black',
cl.pos = 'n',
cl.lim = c(0,1),
na.label = 'square',
na.label.col = 'white',
addgrid.col = 'grey')
corrplot::corrplot(cm.total,
is.corr = T,
method = 'square',
col = cols(10),
addCoef.col = '#542788',
tl.srt = 0,
tl.offset = 1,
number.digits = 2,
tl.cex = 1.2,
cl.cex = 1,
number.cex = 1.5,
tl.col = 'black',
tl.pos = 'n'
cl.pos = 'n',
cl.lim = c(0,1),
na.label = 'square',
na.label.col = 'white',
addgrid.col = 'grey')
par(mfrow = c(1,1))
corrplot::corrplot(cm.total,
is.corr = T,
method = 'square',
col = cols(10),
addCoef.col = '#542788',
tl.srt = 0,
tl.offset = 1,
number.digits = 2,
tl.cex = 1.2,
cl.cex = 1,
number.cex = 1.5,
tl.col = 'black',
tl.pos = 'n',
cl.pos = 'n',
cl.lim = c(0,1),
na.label = 'square',
na.label.col = 'white',
addgrid.col = 'grey')
b = as.data.frame(cm.total)
View(b)
str(B)
str(b)
c = as.matrix(b)
str(c)
corrplot::corrplot(as.matrix(cm.total),
is.corr = F,
method = 'square',
col = cols(10),
addCoef.col = '#542788',
tl.srt = 0,
tl.offset = 1,
number.digits = 2,
tl.cex = 1.2,
cl.cex = 1,
number.cex = 1.5,
tl.col = 'black',
tl.pos = 'n',
cl.pos = 'n',
cl.lim = c(0,1),
na.label = 'square',
na.label.col = 'white',
addgrid.col = 'grey')
packageVersion("corrplot")
install.packages("corrplot")
install.packages("corrplot")
packageVersion("corrplot")
cols = colorRampPalette(c('#f5f5f5', '#fe9929'))
par(mfrow = c(1,1))
corrplot::corrplot(as.matrix(cm.total),
is.corr = F,
method = 'square',
col = cols(10),
addCoef.col = '#542788',
tl.srt = 0,
tl.offset = 1,
number.digits = 2,
tl.cex = 1.2,
cl.cex = 1,
number.cex = 1.5,
tl.col = 'black',
tl.pos = 'n',
cl.pos = 'n',
cl.lim = c(0,1),
na.label = 'square',
na.label.col = 'white',
addgrid.col = 'grey')
corrplot::corrplot(as.matrix(cm.total),
is.corr = F,
method = 'square',
col = cols(10),
addCoef.col = '#542788',
tl.srt = 0,
tl.offset = 1,
number.digits = 0,
tl.cex = 1.2,
cl.cex = 1,
number.cex = 1.5,
tl.col = 'black',
tl.pos = 'n',
cl.pos = 'n',
cl.lim = c(0,1),
na.label = 'square',
na.label.col = 'white',
addgrid.col = 'grey')
?corrplot
corrplot::corrplot(as.matrix(cm.total),
is.corr = F,
method = 'square',
col = cols(10),
addCoef.col = '#542788',
tl.srt = 0,
tl.offset = 1,
number.digits = NULL,
tl.cex = 1.2,
cl.cex = 1,
number.cex = 1.5,
tl.col = 'black',
tl.pos = 'n',
cl.pos = 'n',
cl.lim = c(0,1),
na.label = 'square',
na.label.col = 'white',
addgrid.col = 'grey')
